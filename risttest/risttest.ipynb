{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIST Internship Test - Nichita Uțiu\n",
    "In this document we will try to train a model to predict the type of a sorting algorithm based on a visual representation of it over 42 iterations on a vector of 10 elements(each iteration being a swap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import needed libraries\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# needed for image export\n",
    "import PIL\n",
    "\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel410</th>\n",
       "      <th>pixel411</th>\n",
       "      <th>pixel412</th>\n",
       "      <th>pixel413</th>\n",
       "      <th>pixel414</th>\n",
       "      <th>pixel415</th>\n",
       "      <th>pixel416</th>\n",
       "      <th>pixel417</th>\n",
       "      <th>pixel418</th>\n",
       "      <th>pixel419</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.492175</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.512111</td>\n",
       "      <td>0.500150</td>\n",
       "      <td>0.497343</td>\n",
       "      <td>0.503398</td>\n",
       "      <td>0.498808</td>\n",
       "      <td>0.489210</td>\n",
       "      <td>0.510043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499388</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.500087</td>\n",
       "      <td>0.498844</td>\n",
       "      <td>0.497845</td>\n",
       "      <td>0.497845</td>\n",
       "      <td>0.498844</td>\n",
       "      <td>0.500087</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.499388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.293948</td>\n",
       "      <td>0.290994</td>\n",
       "      <td>0.294248</td>\n",
       "      <td>0.290129</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.288480</td>\n",
       "      <td>0.290329</td>\n",
       "      <td>0.290039</td>\n",
       "      <td>0.285080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416720</td>\n",
       "      <td>0.337148</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>0.194865</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.194865</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>0.337148</td>\n",
       "      <td>0.416720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.253975</td>\n",
       "      <td>0.259150</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.237625</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.268175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.163250</td>\n",
       "      <td>0.256525</td>\n",
       "      <td>0.341550</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>0.341550</td>\n",
       "      <td>0.256525</td>\n",
       "      <td>0.163250</td>\n",
       "      <td>0.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.512050</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>0.512950</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.483250</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>0.506850</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.506850</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>0.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.751150</td>\n",
       "      <td>0.750525</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.752225</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>0.746925</td>\n",
       "      <td>0.732625</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933675</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.650725</td>\n",
       "      <td>0.607250</td>\n",
       "      <td>0.607250</td>\n",
       "      <td>0.650725</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.933675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel0        pixel1        pixel2        pixel3  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.492175      0.498129      0.512111      0.500150   \n",
       "std        2.872425      0.293948      0.290994      0.294248      0.290129   \n",
       "min        0.000000      0.000400      0.000500      0.000300      0.001200   \n",
       "25%        2.000000      0.232000      0.253100      0.253100      0.253975   \n",
       "50%        4.500000      0.491900      0.490000      0.512050      0.494800   \n",
       "75%        7.000000      0.751150      0.750525      0.771700      0.752225   \n",
       "max        9.000000      1.000000      0.997700      0.999400      0.999800   \n",
       "\n",
       "             pixel4        pixel5        pixel6        pixel7        pixel8  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.497343      0.503398      0.498808      0.489210      0.510043   \n",
       "std        0.280255      0.288480      0.290329      0.290039      0.285080   \n",
       "min        0.000300      0.000000      0.000100      0.000400      0.001800   \n",
       "25%        0.259150      0.254000      0.237625      0.243000      0.268175   \n",
       "50%        0.496650      0.512950      0.500700      0.483250      0.513550   \n",
       "75%        0.735500      0.749125      0.746925      0.732625      0.750600   \n",
       "max        0.996100      0.997400      0.998200      0.999300      0.999500   \n",
       "\n",
       "           ...           pixel410      pixel411      pixel412      pixel413  \\\n",
       "count      ...       10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       ...           0.499388      0.500035      0.500087      0.498844   \n",
       "std        ...           0.416720      0.337148      0.261106      0.194865   \n",
       "min        ...           0.000000      0.002900      0.015400      0.062500   \n",
       "25%        ...           0.065600      0.163250      0.256525      0.341550   \n",
       "50%        ...           0.458600      0.486250      0.506850      0.502200   \n",
       "75%        ...           0.933675      0.842000      0.738300      0.650725   \n",
       "max        ...           1.000000      0.993900      0.987100      0.942800   \n",
       "\n",
       "           pixel414      pixel415      pixel416      pixel417      pixel418  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.497845      0.497845      0.498844      0.500087      0.500035   \n",
       "std        0.151147      0.151147      0.194865      0.261106      0.337148   \n",
       "min        0.085000      0.085000      0.062500      0.015400      0.002900   \n",
       "25%        0.392675      0.392675      0.341550      0.256525      0.163250   \n",
       "50%        0.497650      0.497650      0.502200      0.506850      0.486250   \n",
       "75%        0.607250      0.607250      0.650725      0.738300      0.842000   \n",
       "max        0.890600      0.890600      0.942800      0.987100      0.993900   \n",
       "\n",
       "           pixel419  \n",
       "count  10000.000000  \n",
       "mean       0.499388  \n",
       "std        0.416720  \n",
       "min        0.000000  \n",
       "25%        0.065600  \n",
       "50%        0.458600  \n",
       "75%        0.933675  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 421 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithms_df = pd.read_csv('./data.csv')  # load the data from  the csv\n",
    "algorithms_df.describe()  # view a short summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Splitting and looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 10\n",
      "Samples with label 0: 1000\n",
      "Samples with label 1: 1000\n",
      "Samples with label 2: 1000\n",
      "Samples with label 3: 1000\n",
      "Samples with label 4: 1000\n",
      "Samples with label 5: 1000\n",
      "Samples with label 6: 1000\n",
      "Samples with label 7: 1000\n",
      "Samples with label 8: 1000\n",
      "Samples with label 9: 1000\n"
     ]
    }
   ],
   "source": [
    "Y = algorithms_df['label'].astype(int)  # the labels\n",
    "X = algorithms_df.drop('label', axis=1)  # everyhing but the labels\n",
    "\n",
    "# count by label\n",
    "print(\"Number of labels = {}\".format(Y.unique().size))\n",
    "\n",
    "# iterate over the label,count pairs\n",
    "# use sort_index as value_counts returns them unordered\n",
    "for ind, cnt in Y.value_counts().sort_index().iteritems():\n",
    "    print(\"Samples with label {}: {}\".format(ind, cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order(arr):\n",
    "    \"\"\"Returns whether the elements of the given numpy\n",
    "    array are ascending, descending or unordered.\n",
    "    \n",
    "    :return `-1` if descending, `1` if ascending, `0` if\n",
    "    ordered\n",
    "    \"\"\"\n",
    "    # compare elements pairwise\n",
    "    # using numpy for vectorisation\n",
    "    if np.all(arr[:-1] <= arr[1:]):\n",
    "        return 1 # ascending \n",
    "    if np.all(arr[:-1] >= arr[1:]):\n",
    "        return -1 # descending \n",
    "    return 0\n",
    "\n",
    "def get_samp_order(samp, width):\n",
    "    \"\"\"Recives a sample and returns it's last row's\n",
    "    order. Receives the width of the rows, considering\n",
    "    the image is unrolled.\"\"\"\n",
    "    return get_order(samp[-width:])\n",
    "\n",
    "def get_image_from_sample(samp, width):\n",
    "    \"\"\"Returns a PIL grayscale image from the sample\"\"\"\n",
    "    # normalize the values to a set of equally spaced values\n",
    "    # in the (0, 255) interval, to maximize visibility\n",
    "    # we'll be using sklearn's label encoder for this\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    norm_samp = le.fit_transform(samp) * 255 / (width-1)\n",
    "    norm_samp = norm_samp.astype('uint8')\n",
    "    \n",
    "    # convert the array to a pil \"luminance\" image\n",
    "    img =  PIL.Image.new('L', (width, samp.size // width))  # greyscale\n",
    "    img.putdata(norm_samp)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exmaple:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 234 order: 1 \n",
      "Last row = [ 0.056   0.0636  0.16    0.4325  0.4564  0.5976  0.6092  0.6958  0.7046\n",
      "  0.8454]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAAFWCAYAAABaVaLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npiAMUxCGKQjDFIRhCsIwBWGYgvwf+t2EXVpLfZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b37f6bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_IND = 234\n",
    "IMG_WIDTH = 10\n",
    "\n",
    "# get the sample\n",
    "sample = X.iloc[SAMPLE_IND].values\n",
    "\n",
    "order = get_samp_order(sample, IMG_WIDTH)\n",
    "print(\"Sample {} order: {} \".format(SAMPLE_IND, order))\n",
    "print(\"Last row = {}\".format(sample[-IMG_WIDTH:]))  # get the last row\n",
    "\n",
    "# get image from array\n",
    "img = get_image_from_sample(sample, IMG_WIDTH)\n",
    "plt.imshow(img)\n",
    "\n",
    "# save to png\n",
    "img.save(\"algo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature extraction\n",
    "### 3.1 FTD, FTP, NIT, RPA\n",
    "#### 3.1.1 Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ftds(samps, width):\n",
    "    \"\"\"Extracts for each sample, the first row where\n",
    "    each each element changes its initial position.\n",
    "    \n",
    "    :returns a matrix of where each row is the features\n",
    "    of each sample\n",
    "    \"\"\"\n",
    "    # define the function for a single row\n",
    "    def extract_ftd(samp):\n",
    "        img = samp.reshape((-1, width)) # reverse into a matrix\n",
    "        # check what elements on each row are dfferent to the first\n",
    "        # that means that the first True value is the first swap\n",
    "        changes = img != img[0]\n",
    "        # return the row index of the change\n",
    "        return np.argmax(changes, axis=0)\n",
    "    # vectorize it\n",
    "    return np.apply_along_axis(extract_ftd, 1, samps)\n",
    " \n",
    "    \n",
    "def extract_ftps(samps, width):\n",
    "    \"\"\"Extracts for each sample, the first row where\n",
    "    each element reaches it's final position.\n",
    "    \n",
    "    :returns a matrix of where each row is the features\n",
    "    of each sample\"\"\"\n",
    "    # same as above\n",
    "    def extract_ftp(samp):\n",
    "        img = samp.reshape((-1, width))\n",
    "        # however this time check them in reverse\n",
    "        changes = (img != img[-1])[::-1, :]\n",
    "        # return the row index of the change\n",
    "        # substract from len to get the actual postion\n",
    "        return changes.shape[0] - np.argmax(changes, axis=0)\n",
    "\n",
    "    return np.apply_along_axis(extract_ftp, 1, samps)\n",
    "\n",
    "\n",
    "def extract_rpas(samps, width):\n",
    "    \"\"\"Extracts for each sample, the area of image\n",
    "    where the algorithm is active.\n",
    "    \n",
    "    :returns a matrix of the areas for each\n",
    "    corresponding row\"\"\"\n",
    "    # use the ftp features, sum them to get the inactive\n",
    "    # area and substract it from the total\n",
    "    # note: the vectorized computation is fast enough\n",
    "    # not to warrant precalculating ftp\n",
    "    inactive_area = extract_ftps(samps, width).sum(axis=1)\n",
    "    \n",
    "    # substract them from the total size of an image\n",
    "    # also add a dimension to convert it to a matrix\n",
    "    return (samps[0].size - inactive_area)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def extract_nits(samps, width):\n",
    "    \"\"\"Extract, for each sample, the number of iterations\n",
    "    needed to reach the end of the algorithm\n",
    "    \n",
    "    :returns a matrix of the values, each row orresponding to\n",
    "    a sample\n",
    "    \"\"\"\n",
    "    # compute it similarly to the ftp values, but find the \n",
    "    # first row not equal to the last one\n",
    "    def extract_nit(samp):\n",
    "        img = samp.reshape((-1, width))\n",
    "        # any item that is different from the final state\n",
    "        # means the algorithm is still active\n",
    "        changes = np.any((img != img[-1])[::-1, :], axis=1)\n",
    "        return changes.size - np.argmax(changes)\n",
    "    \n",
    "    # vectorize and turn back to a matrix\n",
    "    return np.apply_along_axis(extract_nit, 1, samps)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Example\n",
    "Extract FTD, FTP, NIT and RPA for *SAMPLE_INDEX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features:\n",
      "FTP = [[27 27 25 23 21 18 15 12  8  5]]\n",
      "FTD = [[5 9 1 3 4 1 2 3 8 4]]\n",
      "NIT = [[27]]\n",
      "RPA = [[239]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAAFWCAYAAABaVaLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npiAMUxCGKQjDFIRhCsIwBWGYgvwf+t2EXVpLfZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b376b36a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = X.iloc[SAMPLE_IND].values[np.newaxis, :]\n",
    "\n",
    "ftp = extract_ftps(sample, IMG_WIDTH)\n",
    "ftd = extract_ftds(sample, IMG_WIDTH)\n",
    "nit = extract_nits(sample, IMG_WIDTH)\n",
    "rpa = extract_rpas(sample, IMG_WIDTH)\n",
    "\n",
    "print(\"Extracted features:\")\n",
    "print(\"FTP = {}\".format(ftp))\n",
    "print(\"FTD = {}\".format(ftd))\n",
    "print(\"NIT = {}\".format(nit))\n",
    "print(\"RPA = {}\".format(rpa))\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Additional Features\n",
    "To extract more info from he given features and increase the variance of our samples, we can:\n",
    "\n",
    "* Add a one-hot encoded feature from the order of the last row. This one would be linearly correlated to whether the algorithm is ascending or descending.(**Note:** Is this considered cheating?)\n",
    "\n",
    "* Compute for each element, the time between the first displacement and the time it reaches its last position.\n",
    "(**Note**: Is there an issue of this being a linear combination of the orther features?)\n",
    "\n",
    "* Compute the distance of each swap between every consecutive row. Diferent algorithm might do swaps differently.\n",
    "\n",
    "* Lastly, it could probably help if the values are normalize to an interval and equally spaced so that we extract only the relative order and not the absolut values, reducing noise.\n",
    "\n",
    "#### 3.2.1 Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_orders_one_hot(samps, width):\n",
    "    \"\"\"Extracts the order of the samples as \n",
    "    a matrix of one-hot-encoded values of the \n",
    "    order of the last row\n",
    "    \n",
    "    :returns a matrix of the values, each row \n",
    "    corresponding to a sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # use the predefined function, but vectorize it\n",
    "    # needs positive values so add one\n",
    "    row_func = lambda samp: get_samp_order(samp, width) + 1\n",
    "    samp_orders = np.apply_along_axis(row_func, 1, samps)\n",
    "    \n",
    "    # convert it back to a matrix from a vector\n",
    "    samp_orders = samp_orders.reshape((-1, 1))\n",
    "    \n",
    "    # use sklearn for one-hot encoding\n",
    "    # do not generate sparse matrix\n",
    "    oh_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "    return oh_encoder.fit_transform(samp_orders)\n",
    "\n",
    "\n",
    "def extract_displacements(samps, width):\n",
    "    \"\"\"Returns the displacement for each element \n",
    "    of the array(the differene between FTD and FTP)\n",
    "    \n",
    "    :returns a matrix of the features for each\n",
    "    element of the array on each row\"\"\"\n",
    "    return extract_ftps(samps, width) - \\\n",
    "        extract_ftds(samps, width)\n",
    "\n",
    "\n",
    "def extract_swap_dists(samps, width):\n",
    "    \"\"\"Extracts the distances of swaps between\n",
    "    consecutive rows. The distance is 0 if no \n",
    "    swap occured.\n",
    "    \n",
    "    :returns a matrix of the values, each row \n",
    "    having nrrows-1 columns, each representing \n",
    "    the distance of a swap.\"\"\"\n",
    "    def extract_swap_dist(samp):\n",
    "        img = samp.reshape((-1, width))\n",
    "        # each row will have a truth value where\n",
    "        # the swapped values are\n",
    "        swaps = img[:-1] != img[1:]\n",
    "        \n",
    "        # every pair is the positions on the row\n",
    "        # so sumbstract them to get the distance\n",
    "        pos = np.nonzero(swaps)[1]\n",
    "        swap_lengths = np.abs(pos[::2] - pos[1::2])\n",
    "        \n",
    "        # pad the result with 0 to make them of equal \n",
    "        result = np.zeros(img.shape[0]-1)  # length(41 in this case)\n",
    "        result[:swap_lengths.size] = swap_lengths\n",
    "        return result\n",
    "    \n",
    "    # vectorize and turn back to a matrix\n",
    "    return np.apply_along_axis(extract_swap_dist, 1, samps)\n",
    "\n",
    "\n",
    "def extract_norm_samps(samps, width):\n",
    "    \"\"\"For each image, extract the pixel values,\n",
    "    but normalized to the integer inteval 1, 2 ...width.\n",
    "    \n",
    "    :returns a matrix of the normlized samples, each row\n",
    "    corresponding to each sample\"\"\"\n",
    "    def extract_norm_samp(samp):\n",
    "        # normalize using sklearn's label encoder\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        return le.fit_transform(samp)\n",
    "    \n",
    "    return np.apply_along_axis(extract_norm_samp, 1, samps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Example\n",
    "Extract the bonus features for *SAMPLE_INDEX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features:\n",
      "ORDERS = [[ 1.]]\n",
      "DISPLACEMENTS = [[22 18 24 20 17 17 13  9  0  1]]\n",
      "DISTS = [[ 3.  4.  4.  5.  9.  2.  4.  8.  1.  2.  4.  7.  1.  2.  6.  1.  2.  5.\n",
      "   1.  3.  4.  2.  3.  1.  2.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]]\n",
      "NORM = [[9 7 0 5 1 3 8 6 4 2 9 7 3 5 1 0 8 6 4 2 9 7 8 5 1 0 3 6 4 2 9 7 8 6 1 0 3\n",
      "  5 4 2 9 7 8 6 2 0 3 5 4 1 1 7 8 6 2 0 3 5 4 9 8 7 1 6 2 0 3 5 4 9 8 7 3 6\n",
      "  2 0 1 5 4 9 4 7 3 6 2 0 1 5 8 9 7 4 3 6 2 0 1 5 8 9 7 6 3 4 2 0 1 5 8 9 7\n",
      "  6 3 5 2 0 1 4 8 9 4 6 3 5 2 0 1 7 8 9 6 4 3 5 2 0 1 7 8 9 6 5 3 4 2 0 1 7\n",
      "  8 9 1 5 3 4 2 0 6 7 8 9 5 1 3 4 2 0 6 7 8 9 5 4 3 1 2 0 6 7 8 9 0 4 3 1 2\n",
      "  5 6 7 8 9 4 0 3 1 2 5 6 7 8 9 4 2 3 1 0 5 6 7 8 9 0 2 3 1 4 5 6 7 8 9 3 2\n",
      "  0 1 4 5 6 7 8 9 1 2 0 3 4 5 6 7 8 9 2 1 0 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8\n",
      "  9 1 0 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n",
      "  6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n",
      "  3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n",
      "  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6\n",
      "  7 8 9 0 1 2 3 4 5 6 7 8 9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAAFWCAYAAABaVaLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npiAMUxCGKQjDFIRhCsIwBWGYgvwf+t2EXVpLfZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b37634710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = X.iloc[SAMPLE_IND].values[np.newaxis, :]\n",
    "\n",
    "orders_one_hot = extract_orders_one_hot(sample, IMG_WIDTH)\n",
    "displacements = extract_displacements(sample, IMG_WIDTH)\n",
    "dists = extract_swap_dists(sample, IMG_WIDTH)\n",
    "norm = extract_norm_samps(sample, IMG_WIDTH)\n",
    "\n",
    "print(\"Extracted features:\")\n",
    "print(\"ORDERS = {}\".format(orders_one_hot))\n",
    "print(\"DISPLACEMENTS = {}\".format(displacements))\n",
    "print(\"DISTS = {}\".format(dists))\n",
    "print(\"NORM = {}\".format(norm))\n",
    "\n",
    "plt.imshow(img);  # image for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

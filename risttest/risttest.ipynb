{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIST Internship Test - Nichita Uțiu\n",
    "In this document we will try to train a model to predict the type of a sorting algorithm based on a visual representation of it over 42 iterations on a vector of 10 elements(each iteration being a swap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import needed libraries\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# needed for image export\n",
    "import PIL\n",
    "\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel410</th>\n",
       "      <th>pixel411</th>\n",
       "      <th>pixel412</th>\n",
       "      <th>pixel413</th>\n",
       "      <th>pixel414</th>\n",
       "      <th>pixel415</th>\n",
       "      <th>pixel416</th>\n",
       "      <th>pixel417</th>\n",
       "      <th>pixel418</th>\n",
       "      <th>pixel419</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.492175</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.512111</td>\n",
       "      <td>0.500150</td>\n",
       "      <td>0.497343</td>\n",
       "      <td>0.503398</td>\n",
       "      <td>0.498808</td>\n",
       "      <td>0.489210</td>\n",
       "      <td>0.510043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499388</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.500087</td>\n",
       "      <td>0.498844</td>\n",
       "      <td>0.497845</td>\n",
       "      <td>0.497845</td>\n",
       "      <td>0.498844</td>\n",
       "      <td>0.500087</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.499388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.293948</td>\n",
       "      <td>0.290994</td>\n",
       "      <td>0.294248</td>\n",
       "      <td>0.290129</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.288480</td>\n",
       "      <td>0.290329</td>\n",
       "      <td>0.290039</td>\n",
       "      <td>0.285080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416720</td>\n",
       "      <td>0.337148</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>0.194865</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.194865</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>0.337148</td>\n",
       "      <td>0.416720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.253975</td>\n",
       "      <td>0.259150</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.237625</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.268175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.163250</td>\n",
       "      <td>0.256525</td>\n",
       "      <td>0.341550</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>0.341550</td>\n",
       "      <td>0.256525</td>\n",
       "      <td>0.163250</td>\n",
       "      <td>0.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.512050</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>0.512950</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.483250</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>0.506850</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.506850</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>0.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.751150</td>\n",
       "      <td>0.750525</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.752225</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>0.746925</td>\n",
       "      <td>0.732625</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933675</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.650725</td>\n",
       "      <td>0.607250</td>\n",
       "      <td>0.607250</td>\n",
       "      <td>0.650725</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.933675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel0        pixel1        pixel2        pixel3  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.492175      0.498129      0.512111      0.500150   \n",
       "std        2.872425      0.293948      0.290994      0.294248      0.290129   \n",
       "min        0.000000      0.000400      0.000500      0.000300      0.001200   \n",
       "25%        2.000000      0.232000      0.253100      0.253100      0.253975   \n",
       "50%        4.500000      0.491900      0.490000      0.512050      0.494800   \n",
       "75%        7.000000      0.751150      0.750525      0.771700      0.752225   \n",
       "max        9.000000      1.000000      0.997700      0.999400      0.999800   \n",
       "\n",
       "             pixel4        pixel5        pixel6        pixel7        pixel8  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.497343      0.503398      0.498808      0.489210      0.510043   \n",
       "std        0.280255      0.288480      0.290329      0.290039      0.285080   \n",
       "min        0.000300      0.000000      0.000100      0.000400      0.001800   \n",
       "25%        0.259150      0.254000      0.237625      0.243000      0.268175   \n",
       "50%        0.496650      0.512950      0.500700      0.483250      0.513550   \n",
       "75%        0.735500      0.749125      0.746925      0.732625      0.750600   \n",
       "max        0.996100      0.997400      0.998200      0.999300      0.999500   \n",
       "\n",
       "           ...           pixel410      pixel411      pixel412      pixel413  \\\n",
       "count      ...       10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       ...           0.499388      0.500035      0.500087      0.498844   \n",
       "std        ...           0.416720      0.337148      0.261106      0.194865   \n",
       "min        ...           0.000000      0.002900      0.015400      0.062500   \n",
       "25%        ...           0.065600      0.163250      0.256525      0.341550   \n",
       "50%        ...           0.458600      0.486250      0.506850      0.502200   \n",
       "75%        ...           0.933675      0.842000      0.738300      0.650725   \n",
       "max        ...           1.000000      0.993900      0.987100      0.942800   \n",
       "\n",
       "           pixel414      pixel415      pixel416      pixel417      pixel418  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.497845      0.497845      0.498844      0.500087      0.500035   \n",
       "std        0.151147      0.151147      0.194865      0.261106      0.337148   \n",
       "min        0.085000      0.085000      0.062500      0.015400      0.002900   \n",
       "25%        0.392675      0.392675      0.341550      0.256525      0.163250   \n",
       "50%        0.497650      0.497650      0.502200      0.506850      0.486250   \n",
       "75%        0.607250      0.607250      0.650725      0.738300      0.842000   \n",
       "max        0.890600      0.890600      0.942800      0.987100      0.993900   \n",
       "\n",
       "           pixel419  \n",
       "count  10000.000000  \n",
       "mean       0.499388  \n",
       "std        0.416720  \n",
       "min        0.000000  \n",
       "25%        0.065600  \n",
       "50%        0.458600  \n",
       "75%        0.933675  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 421 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithms_df = pd.read_csv('./data.csv')  # load the data from  the csv\n",
    "algorithms_df.describe()  # view a short summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Splitting and looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 10\n",
      "Samples with label 0: 1000\n",
      "Samples with label 1: 1000\n",
      "Samples with label 2: 1000\n",
      "Samples with label 3: 1000\n",
      "Samples with label 4: 1000\n",
      "Samples with label 5: 1000\n",
      "Samples with label 6: 1000\n",
      "Samples with label 7: 1000\n",
      "Samples with label 8: 1000\n",
      "Samples with label 9: 1000\n"
     ]
    }
   ],
   "source": [
    "Y = algorithms_df['label'].astype(int)  # the labels\n",
    "X = algorithms_df.drop('label', axis=1)  # everyhing but the labels\n",
    "\n",
    "# count by label\n",
    "print(\"Number of labels = {}\".format(Y.unique().size))\n",
    "\n",
    "# iterate over the label,count pairs\n",
    "# use sort_index as value_counts returns them unordered\n",
    "for ind, cnt in Y.value_counts().sort_index().iteritems():\n",
    "    print(\"Samples with label {}: {}\".format(ind, cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order(arr):\n",
    "    \"\"\"Returns whether the elements of the given numpy\n",
    "    array are ascending, descending or unordered.\n",
    "    \n",
    "    :return `-1` if descending, `1` if ascending, `0` if\n",
    "    ordered\n",
    "    \"\"\"\n",
    "    # compare elements pairwise\n",
    "    # using numpy for vectorisation\n",
    "    if np.all(arr[:-1] <= arr[1:]):\n",
    "        return 1 # ascending \n",
    "    if np.all(arr[:-1] >= arr[1:]):\n",
    "        return -1 # descending \n",
    "    return 0\n",
    "\n",
    "def get_samp_order(samp, width):\n",
    "    \"\"\"Recives a sample and returns it's last row's\n",
    "    order. Receives the width of the rows, considering\n",
    "    the image is unrolled.\"\"\"\n",
    "    return get_order(samp[-width:])\n",
    "\n",
    "def get_image_from_sample(samp, width):\n",
    "    \"\"\"Returns a PIL grayscale image from the sample\"\"\"\n",
    "    # normalize the values to a set of equally spaced values\n",
    "    # in the (0, 255) interval\n",
    "    # we'll be using sklearn's label encoder for this\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    norm_samp = le.fit_transform(samp) * 255 / (width-1)\n",
    "    norm_samp = norm_samp.astype('uint8')\n",
    "    \n",
    "    # convert the array to a pil \"luminance\" image\n",
    "    img =  PIL.Image.new('L', (width, samp.size // width))  # greyscale\n",
    "    img.putdata(norm_samp)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exmaple:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 200 order: 1 \n",
      "Last row = [ 0.124   0.252   0.3605  0.3906  0.3948  0.4132  0.5714  0.6346  0.7063\n",
      "  0.7358]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAAFWCAYAAABaVaLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8306b3a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_IND = 200\n",
    "IMG_WIDTH = 10\n",
    "\n",
    "# get the sample\n",
    "sample = X.iloc[SAMPLE_IND].values\n",
    "\n",
    "order = get_samp_order(sample, IMG_WIDTH)\n",
    "print(\"Sample {} order: {} \".format(SAMPLE_IND, order))\n",
    "print(\"Last row = {}\".format(sample[-IMG_WIDTH:]))  # get the last row\n",
    "\n",
    "# get image from array\n",
    "img = get_image_from_sample(sample, IMG_WIDTH)\n",
    "plt.imshow(img)\n",
    "\n",
    "# save to png\n",
    "img.save(\"algo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ftds(samps, width=10):\n",
    "    \"\"\"Extracts for each sample, the first row where\n",
    "    each each element changes its initial position.\n",
    "    \n",
    "    :returns a matrix of where each row is the features\n",
    "    of each sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the function for a single row\n",
    "    def extract_ftd(samp):\n",
    "        img = samp.reshape((-1, width)) # reverse into a matrix\n",
    "        # check what elements on each row are dfferent to the first\n",
    "        # that means that the first True value is the first swap\n",
    "        changes = img != img[0]\n",
    "        # return the row index of the change\n",
    "        return np.argmax(changes, axis=0)\n",
    "    \n",
    "    # vectorize it\n",
    "    return np.apply_along_axis(extract_ftd, 1, samps)\n",
    " \n",
    "    \n",
    "def extract_ftps(samps):\n",
    "    \"\"\"Extracts for each sample, the first row where\n",
    "    each element reaches it's final position.\n",
    "    \n",
    "    :returns a matrix of where each row is the features\n",
    "    of each sample\"\"\"\n",
    "\n",
    "    # same as above\n",
    "    def extract_ftp(samp):\n",
    "        img = samp.reshape((-1, width))\n",
    "        # however this time check them in reverse\n",
    "        changes = (img != img[-1])[::-1, :]\n",
    "        # return the row index of the change\n",
    "        # substract from len to get the actual postion\n",
    "        return changes.shape[0] - np.argmax(changes, axis=0)\n",
    "\n",
    "    return np.apply_along_axis(extract_ftp, 1, samps)\n",
    "\n",
    "def extract_rpas(samps):\n",
    "    \"\"\"Extracts for each sample, the area of image\n",
    "    where the algorithm is active.\n",
    "    \n",
    "    :returns a column vector of the areas for each\n",
    "    corresponding row\"\"\"\n",
    "    \n",
    "    # use the ftp features, sum them to get the inactive\n",
    "    # area and substract it from the total\n",
    "    # note: the vectorized computation is fast enough\n",
    "    # not to warrant precalculating ftp\n",
    "    inactive_area = extract_ftps(samps, width).sum(axis=1)\n",
    "    \n",
    "    # substract them from the total size of an image\n",
    "    # also add a dimension to convert it to a matrix\n",
    "    return (samps[0].size - inactive_area)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Additional Features\n",
    "We can:\n",
    "\n",
    "* Add a one-hot encoded feature from the order of the last row. This one would be linearly correlated to whether the algorithm is ascending or descending. It could also tell apart slower algorithms which may not finish in the given number of iterations.\n",
    "\n",
    "* Compute the total number of swaps for each element before reaching its final pposition. Swap-heavy algorithms such as *bubble-sort* will have higher values than, say, quick-sort in which they will reach their final position in a probably  logaritmic number of steps.\n",
    "(**Note:** I think this could probably correlated to the area of the algorithm, but it might add variance)\n",
    "\n",
    "* Compute the distance of each swap between each row. Diferent algorithm might do swaps differently.\n",
    "\n",
    "* Lastly, it could probably help if the values are normalize to an interval and equally spaced so that we extract only the relative order and not the absolut values, reducing noise.\n",
    "\n",
    "#### Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_order_one_hot(samps, width):\n",
    "    \"\"\"Extracts the order of the samples as \n",
    "    a matrix of one-hot-encoded values of the \n",
    "    order of the last row\"\"\"\n",
    "    \n",
    "    # use the predefined function, but vectorize it\n",
    "    # needs positive values so add one\n",
    "    row_func = lambda samp: get_samp_order(samp, width) + 1\n",
    "    samp_orders = np.apply_along_axis(row_func, 1, samps)\n",
    "    \n",
    "    # convert it back to a matrix from a vector\n",
    "    samp_orders = samp_orders.reshape(-1, 1)\n",
    "    \n",
    "    # use sklearn for one-hot encoding\n",
    "    # do not generate sparse matrix\n",
    "    oh_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "    return oh_encoder.fit_transform(samp_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_order_one_hot(X.values, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
